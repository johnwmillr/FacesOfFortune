{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Faces of Fortune_\n",
    "\n",
    "Determining the average face for the executive boards of each of the top 25 Fortune 500 companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from skimage import io\n",
    "from collections import Counter\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the Selenium browser\n",
    "\n",
    "The Fortune 500 page uses React, so BeautifulSoup HTML parsing won't cut it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john/.virtualenvs/average-faces/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: use options instead of chrome_options\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for endpoints to load...\n"
     ]
    }
   ],
   "source": [
    "# Start a new instance of Chrome\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "browser = webdriver.Chrome('/usr/local/bin/chromedriver', chrome_options=chrome_options)\n",
    "url = \"https://fortune.com/fortune500/search/?\"\n",
    "browser.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# Scroll down to list of endpoints (necessary?)\n",
    "elem = browser.find_element_by_tag_name(\"body\")\n",
    "no_of_pagedowns = 8\n",
    "while no_of_pagedowns:\n",
    "    elem.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(1)\n",
    "    no_of_pagedowns-=1\n",
    "    \n",
    "time.sleep(5)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Fortune 500 page for each company "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the column names from the table\n",
    "name = \"searchResults__columnTitle--1Brf4\"\n",
    "header = browser.find_elements_by_class_name(name)\n",
    "columns = [col.text for col in header]\n",
    "columns.append(\"URL_FORBES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get each row of the table\n",
    "rows = browser.find_elements_by_class_name(\"rt-tr-group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each row in the table, extract the column values\n",
    "link_name = \"searchResults__cellWrapper--39MAj\"\n",
    "data = []\n",
    "for n, row in enumerate(rows, 1):\n",
    "    if n % 20 == 0 or n == 1:\n",
    "        print(f\"({n}/{len(rows)})\")\n",
    "    cells = row.find_elements_by_css_selector(\"div[role='gridcell']\")\n",
    "    values = [cell.text for cell in cells]\n",
    "    \n",
    "    # Get the Fortune URL for the company\n",
    "    link = row.find_element_by_class_name(link_name).get_attribute(\"href\")\n",
    "    values.append(link)\n",
    "    data.append({key:val for key, val in zip(columns, values)})\n",
    "\n",
    "# Store the scraped data as a DataFrame\n",
    "fortune = (pd.DataFrame(data)\n",
    "        .set_index(\"RANK\"))\n",
    "fortune.to_csv(\"Fortune100.csv\")\n",
    "fortune.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load each company's web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>REVENUES ($M)</th>\n",
       "      <th>REVENUE PERCENT CHANGE</th>\n",
       "      <th>PROFITS ($M)</th>\n",
       "      <th>PROFITS PERCENT CHANGE</th>\n",
       "      <th>ASSETS ($M)</th>\n",
       "      <th>MARKET VALUE — AS OF MARCH 29, 2019 ($M)</th>\n",
       "      <th>CHANGE IN RANK (FULL 1000)</th>\n",
       "      <th>EMPLOYEES</th>\n",
       "      <th>CHANGE IN RANK (500 ONLY)</th>\n",
       "      <th>URL_FORBES</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RANK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>$514,405.0</td>\n",
       "      <td>2.8%</td>\n",
       "      <td>$6,670.0</td>\n",
       "      <td>-32.4%</td>\n",
       "      <td>$219,295.0</td>\n",
       "      <td>$279,880.3</td>\n",
       "      <td>-</td>\n",
       "      <td>2,200,000</td>\n",
       "      <td>-</td>\n",
       "      <td>https://fortune.com/fortune500/2019/walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exxon Mobil</td>\n",
       "      <td>$290,212.0</td>\n",
       "      <td>18.8%</td>\n",
       "      <td>$20,840.0</td>\n",
       "      <td>5.7%</td>\n",
       "      <td>$346,196.0</td>\n",
       "      <td>$342,172.0</td>\n",
       "      <td>-</td>\n",
       "      <td>71,000</td>\n",
       "      <td>-</td>\n",
       "      <td>https://fortune.com/fortune500/2019/exxon-mobil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple</td>\n",
       "      <td>$265,595.0</td>\n",
       "      <td>15.9%</td>\n",
       "      <td>$59,531.0</td>\n",
       "      <td>23.1%</td>\n",
       "      <td>$365,725.0</td>\n",
       "      <td>$895,667.4</td>\n",
       "      <td>1</td>\n",
       "      <td>132,000</td>\n",
       "      <td>1</td>\n",
       "      <td>https://fortune.com/fortune500/2019/apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Berkshire Hathaway</td>\n",
       "      <td>$247,837.0</td>\n",
       "      <td>2.4%</td>\n",
       "      <td>$4,021.0</td>\n",
       "      <td>-91.1%</td>\n",
       "      <td>$707,794.0</td>\n",
       "      <td>$493,870.3</td>\n",
       "      <td>-1</td>\n",
       "      <td>389,000</td>\n",
       "      <td>-1</td>\n",
       "      <td>https://fortune.com/fortune500/2019/berkshire-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>$232,887.0</td>\n",
       "      <td>30.9%</td>\n",
       "      <td>$10,073.0</td>\n",
       "      <td>232.1%</td>\n",
       "      <td>$162,648.0</td>\n",
       "      <td>$874,709.5</td>\n",
       "      <td>3</td>\n",
       "      <td>647,500</td>\n",
       "      <td>3</td>\n",
       "      <td>https://fortune.com/fortune500/2019/amazon-com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    NAME REVENUES ($M) REVENUE PERCENT CHANGE PROFITS ($M)  \\\n",
       "RANK                                                                         \n",
       "1                Walmart    $514,405.0                   2.8%     $6,670.0   \n",
       "2            Exxon Mobil    $290,212.0                  18.8%    $20,840.0   \n",
       "3                  Apple    $265,595.0                  15.9%    $59,531.0   \n",
       "4     Berkshire Hathaway    $247,837.0                   2.4%     $4,021.0   \n",
       "5             Amazon.com    $232,887.0                  30.9%    $10,073.0   \n",
       "\n",
       "     PROFITS PERCENT CHANGE ASSETS ($M)  \\\n",
       "RANK                                      \n",
       "1                    -32.4%  $219,295.0   \n",
       "2                      5.7%  $346,196.0   \n",
       "3                     23.1%  $365,725.0   \n",
       "4                    -91.1%  $707,794.0   \n",
       "5                    232.1%  $162,648.0   \n",
       "\n",
       "     MARKET VALUE — AS OF MARCH 29, 2019 ($M) CHANGE IN RANK (FULL 1000)  \\\n",
       "RANK                                                                       \n",
       "1                                  $279,880.3                          -   \n",
       "2                                  $342,172.0                          -   \n",
       "3                                  $895,667.4                          1   \n",
       "4                                  $493,870.3                         -1   \n",
       "5                                  $874,709.5                          3   \n",
       "\n",
       "      EMPLOYEES CHANGE IN RANK (500 ONLY)  \\\n",
       "RANK                                        \n",
       "1     2,200,000                         -   \n",
       "2        71,000                         -   \n",
       "3       132,000                         1   \n",
       "4       389,000                        -1   \n",
       "5       647,500                         3   \n",
       "\n",
       "                                             URL_FORBES  \n",
       "RANK                                                     \n",
       "1           https://fortune.com/fortune500/2019/walmart  \n",
       "2       https://fortune.com/fortune500/2019/exxon-mobil  \n",
       "3             https://fortune.com/fortune500/2019/apple  \n",
       "4     https://fortune.com/fortune500/2019/berkshire-...  \n",
       "5        https://fortune.com/fortune500/2019/amazon-com  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fortune = pd.read_csv(\"./Fortune100.csv\").set_index(\"RANK\")\n",
    "fortune.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the company website for each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://fortune.com/fortune500/2019/walmart\n",
      "https://fortune.com/fortune500/2019/general-electric\n",
      "https://fortune.com/fortune500/2019/ups\n",
      "https://fortune.com/fortune500/2019/pfizer\n",
      "https://fortune.com/fortune500/2019/oracle\n"
     ]
    }
   ],
   "source": [
    "name = \"dataTable__value--3n5tL dataTable__valueAlignLeft--3uvNx\"\n",
    "company_urls = []\n",
    "for num_url, url_forbes in enumerate(fortune[\"URL_FORBES\"]):\n",
    "    if num_url % 20 == 0:\n",
    "        print(url_forbes)\n",
    "    page = requests.get(url_forbes)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "    items = list(map(lambda x: x.find(\"a\"), soup.find_all(class_=name)))\n",
    "    company_url = [item for item in items if item][0].get(\"href\")\n",
    "    company_urls.append(company_url)\n",
    "    time.sleep(1)\n",
    "\n",
    "# Update the DataFrame\n",
    "fortune[\"URL_COMPANY\"] = company_urls\n",
    "fortune.to_csv(\"Fortune100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "fortune = pd.read_csv(\"./Fortune100.csv\").set_index(\"RANK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify each company's leadership page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_search_url(company):\n",
    "    return f\"https://www.google.com/search?q={company}+corporate+leadership+page\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Google leadership search URLs to the DataFrame\n",
    "fortune[\"SEARCH_URL\"] = fortune[\"NAME\"].apply(get_google_search_url)\n",
    "\n",
    "# Strip the HTTPS stuff from the front of the company URL\n",
    "fortune[\"URL_DOMAIN\"] = fortune[\"URL_COMPANY\"].apply(lambda x: \".\" + x.rsplit(\".\", 1)[-1])\n",
    "fortune[\"URL_COMPANY_SUFFIX\"] = fortune[\"URL_COMPANY\"].apply(lambda x: \".\".join(x.rsplit(\".\")[1:]))\n",
    "fortune.to_csv(\"./Fortune100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get each company's (likely) leadership page from Google searches\n",
    "leadership_urls = []\n",
    "cols = [\"NAME\", \"URL_COMPANY_SUFFIX\", \"SEARCH_URL\"]\n",
    "for rank, (company, suffix, url) in fortune[cols].iterrows():\n",
    "    if rank % 20 == 0 or rank == 1:\n",
    "        print(f\"({rank:2.0f}/{fortune.index.max()}): {company}\")\n",
    "        \n",
    "    # Open the Google search page in Selenium\n",
    "    browser.get(url)\n",
    "    time.sleep(3)\n",
    "    hits = browser.find_elements_by_class_name(\"bkWMgd\")\n",
    "    \n",
    "    # Loop through the top hits on the page\n",
    "    leadership_url = None\n",
    "    for hit in hits:\n",
    "        try:\n",
    "            r = hit.find_element_by_class_name(\"r\")\n",
    "        except:\n",
    "            continue\n",
    "        hit_url = r.find_element_by_css_selector(\"a\").get_attribute(\"href\")\n",
    "        if suffix in hit_url:\n",
    "            leadership_url = hit_url\n",
    "            break\n",
    "    leadership_urls.append(leadership_url)\n",
    "    \n",
    "# Update the DataFrame\n",
    "fortune[\"URL_LEADERSHIP\"] = leadership_urls\n",
    "fortune.to_csv(\"Fortune100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually add the leadership URLs we missed\n",
    "col = \"URL_LEADERSHIP\"\n",
    "fortune.loc[4, col] = \"https://www.berkshirehathawayhs.com/pages/about\"\n",
    "fortune.loc[9, col] = \"https://investors.att.com/corporate-governance/leadership\"\n",
    "fortune.loc[12, col] = \"https://media.ford.com/content/fordmedia/fna/us/en/people.filter.company-officers.0.50.html\" # Might need manual work\n",
    "fortune.loc[15, col] = \"https://abc.xyz/investor/other/board/#\" # Need to Google image search the names\n",
    "fortune.loc[20, col] = \"http://ir.kroger.com/management-and-directors\" # Need to Google image search the names\n",
    "fortune.loc[32, col] = \"https://www.cmcsa.com/corporate-governance/executive-officers\" # Requires manual work\n",
    "fortune.to_csv(\"./Fortune100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the roots for each of the leadership URLs (for image paths later)\n",
    "def get_leadership_url_root(row):\n",
    "    try:\n",
    "        return row[\"URL_LEADERSHIP\"].rsplit(row[\"URL_DOMAIN\"], 1)[0] + row[\"URL_DOMAIN\"]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "fortune[\"URL_LEADERSHIP_ROOT\"] = fortune.apply(get_leadership_url_root, 1)\n",
    "fortune.to_csv(\"./Fortune100.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape all images from each company's leadership page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/52633697/selenium-python-how-to-capture-network-traffics-response\n",
    "class ImageScraper(object):\n",
    "    \n",
    "    def __init__(self, wait_time=1):\n",
    "        # Run this once to start the Chrome instance\n",
    "        caps = DesiredCapabilities.CHROME\n",
    "        caps['loggingPrefs'] = {'performance': 'ALL'}\n",
    "        self.driver = webdriver.Chrome(desired_capabilities=caps)\n",
    "        self.browser_log = None\n",
    "        self.responses = None\n",
    "        self.wait_time = wait_time # seconds\n",
    "        \n",
    "        # Maximize the window\n",
    "        kwargs = dict(x=0, y=0, width=1340, height=900)\n",
    "        self.driver.set_window_rect(**kwargs)\n",
    "        \n",
    "    def _load_page(self, url):\n",
    "        # Load the page\n",
    "        self.driver.delete_all_cookies()\n",
    "        self.driver.get(url)\n",
    "        self.driver.refresh()\n",
    "        self.driver.delete_all_cookies()\n",
    "        self.driver.get(url)\n",
    "        time.sleep(0.2)\n",
    "        \n",
    "        # Scroll to the bottom & top of page, prompting image loads                \n",
    "        elem = self.driver.find_element_by_tag_name(\"body\")\n",
    "        no_of_pagedowns = 10\n",
    "        while no_of_pagedowns:\n",
    "            elem.send_keys(Keys.PAGE_DOWN)\n",
    "            time.sleep(0.8)\n",
    "            no_of_pagedowns-=1\n",
    "        time.sleep(0.5)\n",
    "        for pos in 2 * [\"0\", \"document.body.scrollHeight\"]:\n",
    "            scroll = f\"window.scrollTo(0, {pos});\"\n",
    "            self.driver.execute_script(scroll)\n",
    "            time.sleep(0.2)\n",
    "        time.sleep(0.5)\n",
    "        self.browser_log = self.driver.get_log('performance')\n",
    "        return\n",
    "\n",
    "    def _process_browser_log_entry(self, entry):\n",
    "        return json.loads(entry['message'])['message']\n",
    "\n",
    "    def get_all_image_links(self, url):\n",
    "        \"\"\"Returns a list of all image URLs on the page\"\"\"\n",
    "        self._load_page(url)\n",
    "        \n",
    "        # Parse the network events\n",
    "        events = [self._process_browser_log_entry(entry) for entry in self.browser_log]\n",
    "        events = [event for event in events if 'Network.response' in event['method']]\n",
    "        events = pd.DataFrame([event['params'] for event in events])\n",
    "        responses = pd.DataFrame(events[events.type == \"Image\"]['response'].tolist())\n",
    "        self.responses = responses\n",
    "        return responses['url'].drop_duplicates()\n",
    "    \n",
    "    def close(self):\n",
    "        print(\"Closing browser... \", end=\"\")\n",
    "        self.driver.quit()\n",
    "        print(\"Done.\")        \n",
    "    \n",
    "    def __del__(self):\n",
    "        self.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def shape_or_ratio_is_good(imshape):\n",
    "    return (imshape == most_common_shape) or (get_ratio(imshape) == most_common_ratio)\n",
    "\n",
    "def okay_to_print(num, always_print=False):\n",
    "    return num == 1 or num == N or num % 5 == 0 or always_print\n",
    "\n",
    "def mimeType_is_valid(mimeType):\n",
    "    return mimeType.rsplit(\"/\", 1)[-1].lower() in [\"png\", \"jpg\", \"jpeg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ImageScraper at 0x134d7a8d0>"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the scraper instance, opening Chrome\n",
    "scraper = ImageScraper()\n",
    "scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 1/25): Walmart\n",
      "\thttps://corporate.walmart.com/our-story/leadership\n",
      "Downloaded 54 images.\n",
      "( 2/25): Exxon_Mobil\n",
      "\thttps://corporate.exxonmobil.com/company/who-we-are/management-committee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john/.virtualenvs/average-faces/lib/python3.7/site-packages/PIL/Image.py:993: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 17 images.\n",
      "( 3/25): Apple\n",
      "\thttps://www.apple.com/leadership/\n",
      "Downloaded 19 images.\n",
      "( 4/25): Berkshire_Hathaway\n",
      "\thttps://www.berkshirehathawayhs.com/pages/about\n",
      "Downloaded 1 images.\n",
      "( 5/25): Amazon.com\n",
      "\thttps://ir.aboutamazon.com/board-of-directors\n",
      "Downloaded 21 images.\n",
      "( 6/25): UnitedHealth_Group\n",
      "\thttps://www.unitedhealthgroup.com/about/executives.html\n",
      "Downloaded 3 images.\n",
      "( 7/25): McKesson\n",
      "\thttps://www.mckesson.com/about-mckesson/our-company/executive-officers/\n",
      "Downloaded 14 images.\n",
      "( 8/25): CVS_Health\n",
      "\thttps://cvshealth.com/about/leadership\n",
      "Downloaded 16 images.\n",
      "( 9/25): AT&T\n",
      "\thttps://investors.att.com/corporate-governance/leadership\n",
      "Downloaded 12 images.\n",
      "(10/25): AmerisourceBergen\n",
      "\thttps://www.amerisourcebergen.com/about-our-leadership\n",
      "Downloaded 9 images.\n",
      "(11/25): Chevron\n",
      "\thttps://www.chevron.com/about/leadership\n",
      "Downloaded 0 images.\n",
      "(12/25): Ford_Motor\n",
      "\thttps://media.ford.com/content/fordmedia/fna/us/en/people.filter.company-officers.0.50.html\n",
      "Downloaded 58 images.\n",
      "(13/25): General_Motors\n",
      "\thttps://www.gm.com/our-company/leadership/corporate-officers.html\n",
      "Downloaded 19 images.\n",
      "(14/25): Costco_Wholesale\n",
      "\thttp://investor.costco.com/executive-officers\n",
      "Downloaded 8 images.\n",
      "(15/25): Alphabet\n",
      "\thttps://abc.xyz/investor/other/board/#\n",
      "Downloaded 2 images.\n",
      "(16/25): Cardinal_Health\n",
      "\thttps://www.cardinalhealth.com/en/about-us/our-people/our-leaders.html\n",
      "Downloaded 26 images.\n",
      "(17/25): Walgreens_Boots_Alliance\n",
      "\thttps://www.walgreensbootsalliance.com/about/senior-management/\n",
      "Downloaded 10 images.\n",
      "(18/25): JPMorgan_Chase\n",
      "\thttps://www.jpmorganchase.com/corporate/About-JPMC/operating-committee.htm\n",
      "Downloaded 17 images.\n",
      "(19/25): Verizon_Communications\n",
      "\thttps://www.verizon.com/about/our-company/executive-bios\n",
      "Downloaded 21 images.\n",
      "(20/25): Kroger\n",
      "\thttp://ir.kroger.com/management-and-directors\n",
      "Downloaded 42 images.\n",
      "(21/25): General_Electric\n",
      "\thttps://www.ge.com/about-us/leadership/executives\n",
      "Downloaded 24 images.\n",
      "(22/25): Fannie_Mae\n",
      "\thttps://www.fanniemae.com/portal/about-fm/leadership/fannie-mae-leadership.html\n",
      "Downloaded 14 images.\n",
      "(23/25): Phillips_66\n",
      "\thttps://investor.phillips66.com/corporate-governance/default.aspx\n",
      "Downloaded 25 images.\n",
      "(24/25): Valero_Energy\n",
      "\thttps://www.valero.com/en-us/AboutValero/ExecutiveTeam\n",
      "Downloaded 24 images.\n",
      "(25/25): Bank_of_America\n",
      "\thttps://about.bankofamerica.com/en-us/who-we-are/our-leadership.html\n",
      "Downloaded 34 images.\n",
      "Closing browser... Done.\n"
     ]
    }
   ],
   "source": [
    "# Get the top 25 company's (likely) leadership page from Google searches\n",
    "N = 25\n",
    "cols = [\"NAME\", \"URL_LEADERSHIP\", \"URL_LEADERSHIP_ROOT\"]\n",
    "all_image_links = {}\n",
    "skipped_links = []\n",
    "for rank, (company, url, root) in fortune.head(N)[cols].iterrows():\n",
    "    images = {}\n",
    "    sizes = []\n",
    "    try:\n",
    "        company = company.replace(\" \", \"_\")\n",
    "        if okay_to_print(rank, True):\n",
    "            print(f\"({rank:2.0f}/{N}): {company}\\n\\t{url}\")\n",
    "            \n",
    "        # Get a link to every image on the pank\n",
    "        image_links = scraper.get_all_image_links(url)\n",
    "        valid_links = scraper.responses['mimeType'].apply(mimeType_is_valid)\n",
    "        image_links = image_links[valid_links]\n",
    "        all_image_links[company] = image_links\n",
    "\n",
    "        # Attempt to read each image\n",
    "        for n, image_url in enumerate(image_links):\n",
    "            alt = f\"{company}_image_{n:02.0f}\"\n",
    "            try:\n",
    "                image = io.imread(image_url)[..., ::-1]\n",
    "            except:\n",
    "                skipped_links.append(image_url)\n",
    "                continue\n",
    "\n",
    "            # Keep the image URL, image array, and image size\n",
    "            images[alt] = [image_url, image]\n",
    "            sizes.append(image.shape)\n",
    "        if okay_to_print(rank, True):\n",
    "            print(f\"Downloaded {len(images)} images.\")\n",
    "        if len(images) == 0:\n",
    "            continue\n",
    "\n",
    "        # What's the most common image shape and ratio?\n",
    "        get_ratio = lambda x: round(1000 * x[0] / x[1])\n",
    "        most_common_shape = Counter([s[:2] for s in sizes]).most_common(1)[0][0]\n",
    "        most_common_ratio = Counter(list(map(get_ratio, sizes))).most_common(1)[0][0]\n",
    "\n",
    "        # Create a company images folder if it doesn't already exist\n",
    "        folder = f\"./images/{rank:02.0f}_{company}\"\n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)\n",
    "\n",
    "        # Save all images, but note the ones with questionable ratios\n",
    "        for label, (image_url, array) in images.items():\n",
    "            fn = label\n",
    "            if not shape_or_ratio_is_good(array.shape[:2]):\n",
    "                fn += \"_bad_size\"\n",
    "            fn += \".jpg\"\n",
    "            fp = os.path.join(folder, fn)\n",
    "            cv2.imwrite(fp, array)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error with '{company}':\\n{e}\")\n",
    "    time.sleep(0.5)    \n",
    "# Close the browser\n",
    "scraper.close()\n",
    "del(scraper)\n",
    "\n",
    "# Save the image links\n",
    "with open(f\"fortune_{N}_image_links.pickle\", \"wb\") as outfile:\n",
    "    pickle.dump(all_image_links, outfile)\n",
    "print(\"All done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
