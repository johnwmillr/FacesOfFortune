{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Faces of Fortune_\n",
    "\n",
    "Determining the average face for the executive boards of each of the top 25 Fortune 500 companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from skimage import io\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the Selenium browser\n",
    "\n",
    "The Fortune 500 page uses React, so BeautifulSoup HTML parsing won't cut it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john/.virtualenvs/average-faces/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: use options instead of chrome_options\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for endpoints to load...\n"
     ]
    }
   ],
   "source": [
    "# Start a new instance of Chrome\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "browser = webdriver.Chrome('/usr/local/bin/chromedriver', chrome_options=chrome_options)\n",
    "url = \"https://fortune.com/fortune500/search/?\"\n",
    "browser.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# Scroll down to list of endpoints (necessary?)\n",
    "elem = browser.find_element_by_tag_name(\"body\")\n",
    "no_of_pagedowns = 8\n",
    "while no_of_pagedowns:\n",
    "    elem.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(1)\n",
    "    no_of_pagedowns-=1\n",
    "    \n",
    "time.sleep(5)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Fortune 500 page for each company "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the column names from the table\n",
    "name = \"searchResults__columnTitle--1Brf4\"\n",
    "header = browser.find_elements_by_class_name(name)\n",
    "columns = [col.text for col in header]\n",
    "columns.append(\"URL_FORBES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get each row of the table\n",
    "rows = browser.find_elements_by_class_name(\"rt-tr-group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each row in the table, extract the column values\n",
    "link_name = \"searchResults__cellWrapper--39MAj\"\n",
    "data = []\n",
    "for n, row in enumerate(rows, 1):\n",
    "    if n % 20 == 0 or n == 1:\n",
    "        print(f\"({n}/{len(rows)})\")\n",
    "    cells = row.find_elements_by_css_selector(\"div[role='gridcell']\")\n",
    "    values = [cell.text for cell in cells]\n",
    "    \n",
    "    # Get the Fortune URL for the company\n",
    "    link = row.find_element_by_class_name(link_name).get_attribute(\"href\")\n",
    "    values.append(link)\n",
    "    data.append({key:val for key, val in zip(columns, values)})\n",
    "\n",
    "# Store the scraped data as a DataFrame\n",
    "df = (pd.DataFrame(data)\n",
    "        .set_index(\"RANK\"))\n",
    "df.to_csv(\"Fortune100.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load each company's web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>REVENUES ($M)</th>\n",
       "      <th>REVENUE PERCENT CHANGE</th>\n",
       "      <th>PROFITS ($M)</th>\n",
       "      <th>PROFITS PERCENT CHANGE</th>\n",
       "      <th>ASSETS ($M)</th>\n",
       "      <th>MARKET VALUE — AS OF MARCH 29, 2019 ($M)</th>\n",
       "      <th>CHANGE IN RANK (FULL 1000)</th>\n",
       "      <th>EMPLOYEES</th>\n",
       "      <th>CHANGE IN RANK (500 ONLY)</th>\n",
       "      <th>URL_FORBES</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RANK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>$514,405.0</td>\n",
       "      <td>2.8%</td>\n",
       "      <td>$6,670.0</td>\n",
       "      <td>-32.4%</td>\n",
       "      <td>$219,295.0</td>\n",
       "      <td>$279,880.3</td>\n",
       "      <td>-</td>\n",
       "      <td>2,200,000</td>\n",
       "      <td>-</td>\n",
       "      <td>https://fortune.com/fortune500/2019/walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exxon Mobil</td>\n",
       "      <td>$290,212.0</td>\n",
       "      <td>18.8%</td>\n",
       "      <td>$20,840.0</td>\n",
       "      <td>5.7%</td>\n",
       "      <td>$346,196.0</td>\n",
       "      <td>$342,172.0</td>\n",
       "      <td>-</td>\n",
       "      <td>71,000</td>\n",
       "      <td>-</td>\n",
       "      <td>https://fortune.com/fortune500/2019/exxon-mobil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple</td>\n",
       "      <td>$265,595.0</td>\n",
       "      <td>15.9%</td>\n",
       "      <td>$59,531.0</td>\n",
       "      <td>23.1%</td>\n",
       "      <td>$365,725.0</td>\n",
       "      <td>$895,667.4</td>\n",
       "      <td>1</td>\n",
       "      <td>132,000</td>\n",
       "      <td>1</td>\n",
       "      <td>https://fortune.com/fortune500/2019/apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Berkshire Hathaway</td>\n",
       "      <td>$247,837.0</td>\n",
       "      <td>2.4%</td>\n",
       "      <td>$4,021.0</td>\n",
       "      <td>-91.1%</td>\n",
       "      <td>$707,794.0</td>\n",
       "      <td>$493,870.3</td>\n",
       "      <td>-1</td>\n",
       "      <td>389,000</td>\n",
       "      <td>-1</td>\n",
       "      <td>https://fortune.com/fortune500/2019/berkshire-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>$232,887.0</td>\n",
       "      <td>30.9%</td>\n",
       "      <td>$10,073.0</td>\n",
       "      <td>232.1%</td>\n",
       "      <td>$162,648.0</td>\n",
       "      <td>$874,709.5</td>\n",
       "      <td>3</td>\n",
       "      <td>647,500</td>\n",
       "      <td>3</td>\n",
       "      <td>https://fortune.com/fortune500/2019/amazon-com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    NAME REVENUES ($M) REVENUE PERCENT CHANGE PROFITS ($M)  \\\n",
       "RANK                                                                         \n",
       "1                Walmart    $514,405.0                   2.8%     $6,670.0   \n",
       "2            Exxon Mobil    $290,212.0                  18.8%    $20,840.0   \n",
       "3                  Apple    $265,595.0                  15.9%    $59,531.0   \n",
       "4     Berkshire Hathaway    $247,837.0                   2.4%     $4,021.0   \n",
       "5             Amazon.com    $232,887.0                  30.9%    $10,073.0   \n",
       "\n",
       "     PROFITS PERCENT CHANGE ASSETS ($M)  \\\n",
       "RANK                                      \n",
       "1                    -32.4%  $219,295.0   \n",
       "2                      5.7%  $346,196.0   \n",
       "3                     23.1%  $365,725.0   \n",
       "4                    -91.1%  $707,794.0   \n",
       "5                    232.1%  $162,648.0   \n",
       "\n",
       "     MARKET VALUE — AS OF MARCH 29, 2019 ($M) CHANGE IN RANK (FULL 1000)  \\\n",
       "RANK                                                                       \n",
       "1                                  $279,880.3                          -   \n",
       "2                                  $342,172.0                          -   \n",
       "3                                  $895,667.4                          1   \n",
       "4                                  $493,870.3                         -1   \n",
       "5                                  $874,709.5                          3   \n",
       "\n",
       "      EMPLOYEES CHANGE IN RANK (500 ONLY)  \\\n",
       "RANK                                        \n",
       "1     2,200,000                         -   \n",
       "2        71,000                         -   \n",
       "3       132,000                         1   \n",
       "4       389,000                        -1   \n",
       "5       647,500                         3   \n",
       "\n",
       "                                             URL_FORBES  \n",
       "RANK                                                     \n",
       "1           https://fortune.com/fortune500/2019/walmart  \n",
       "2       https://fortune.com/fortune500/2019/exxon-mobil  \n",
       "3             https://fortune.com/fortune500/2019/apple  \n",
       "4     https://fortune.com/fortune500/2019/berkshire-...  \n",
       "5        https://fortune.com/fortune500/2019/amazon-com  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./Fortune100.csv\").set_index(\"RANK\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the company website for each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://fortune.com/fortune500/2019/walmart\n",
      "https://fortune.com/fortune500/2019/general-electric\n",
      "https://fortune.com/fortune500/2019/ups\n",
      "https://fortune.com/fortune500/2019/pfizer\n",
      "https://fortune.com/fortune500/2019/oracle\n"
     ]
    }
   ],
   "source": [
    "name = \"dataTable__value--3n5tL dataTable__valueAlignLeft--3uvNx\"\n",
    "company_urls = []\n",
    "for num_url, url_forbes in enumerate(df[\"URL_FORBES\"]):\n",
    "    if num_url % 20 == 0:\n",
    "        print(url_forbes)\n",
    "    page = requests.get(url_forbes)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "    items = list(map(lambda x: x.find(\"a\"), soup.find_all(class_=name)))\n",
    "    company_url = [item for item in items if item][0].get(\"href\")\n",
    "    company_urls.append(company_url)\n",
    "    time.sleep(1)\n",
    "\n",
    "# Update the DataFrame\n",
    "df[\"URL_COMPANY\"] = company_urls\n",
    "df.to_csv(\"Fortune100.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify each company's leadership page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_search_url(company):\n",
    "    return f\"https://www.google.com/search?q={company}+corporate+leadership+page\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Google leadership search URLs to the DataFrame\n",
    "df[\"SEARCH_URL\"] = df[\"NAME\"].apply(get_google_search_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip the HTTPS stuff from the front of the company URL\n",
    "df[\"URL_DOMAIN\"] = df[\"URL_COMPANY\"].apply(lambda x: \".\" + x.rsplit(\".\", 1)[-1])\n",
    "df[\"URL_COMPANY_SUFFIX\"] = df[\"URL_COMPANY\"].apply(lambda x: \".\".join(x.rsplit(\".\")[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get each company's (likely) leadership page from Google searches\n",
    "leadership_urls = []\n",
    "cols = [\"NAME\", \"URL_COMPANY_SUFFIX\", \"SEARCH_URL\"]\n",
    "for rank, (company, suffix, url) in df[cols].iterrows():\n",
    "    if rank % 20 == 0 or rank == 1:\n",
    "        print(f\"({rank:2.0f}/{df.index.max()}): {company}\")\n",
    "        \n",
    "    # Open the Google search page in Selenium\n",
    "    browser.get(url)\n",
    "    time.sleep(3)\n",
    "    hits = browser.find_elements_by_class_name(\"bkWMgd\")\n",
    "    \n",
    "    # Loop through the top hits on the page\n",
    "    leadership_url = None\n",
    "    for hit in hits:\n",
    "        try:\n",
    "            r = hit.find_element_by_class_name(\"r\")\n",
    "        except:\n",
    "            continue\n",
    "        hit_url = r.find_element_by_css_selector(\"a\").get_attribute(\"href\")\n",
    "        if suffix in hit_url:\n",
    "            leadership_url = hit_url\n",
    "            break\n",
    "    leadership_urls.append(leadership_url)\n",
    "    \n",
    "# Update the DataFrame\n",
    "df[\"URL_LEADERSHIP\"] = leadership_urls\n",
    "df.to_csv(\"Fortune100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually add the leadership URLs we missed\n",
    "col = \"URL_LEADERSHIP\"\n",
    "df.loc[4, col] = \"https://www.berkshirehathawayhs.com/pages/about\"\n",
    "df.loc[9, col] = \"https://investors.att.com/corporate-governance/leadership\"\n",
    "df.loc[12, col] = \"https://media.ford.com/content/fordmedia/fna/us/en/people.filter.company-officers.0.50.html\" # Might need manual work\n",
    "df.loc[15, col] = \"https://abc.xyz/investor/other/board/#\" # Need to Google image search the names\n",
    "df.loc[20, col] = \"http://ir.kroger.com/management-and-directors\" # Need to Google image search the names\n",
    "df.loc[32, col] = \"https://www.cmcsa.com/corporate-governance/executive-officers\" # Requires manual work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape all images from each company's leadership page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the roots for each of the leadership URLs (for image paths later)\n",
    "def get_leadership_url_root(row):\n",
    "    try:\n",
    "        return row[\"URL_LEADERSHIP\"].rsplit(row[\"URL_DOMAIN\"], 1)[0] + row[\"URL_DOMAIN\"]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df[\"URL_LEADERSHIP_ROOT\"] = df.apply(get_leadership_url_root, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 1/100): Walmart\n",
      "https://corporate.walmart.com/our-story/leadership\n",
      "(20/100): Kroger\n",
      "http://ir.kroger.com/management-and-directors\n",
      "(25/100): Bank of America\n",
      "https://about.bankofamerica.com/en-us/who-we-are/our-leadership.html\n"
     ]
    }
   ],
   "source": [
    "# Get the top 25 company's (likely) leadership page from Google searches\n",
    "N = 25\n",
    "cols = [\"NAME\", \"URL_LEADERSHIP\", \"URL_LEADERSHIP_ROOT\"]\n",
    "for rank, (company, url, root) in df.head(N)[cols].iterrows():\n",
    "    if rank % 20 == 0 or rank == 1 or rank == 25:\n",
    "        print(f\"({rank:2.0f}/{df.index.max()}): {company}\")\n",
    "        print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape all images from the company's leadership page\n",
    "browser.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the page\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = df.loc[N][\"NAME\"].replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't read: 'Bank_of_America_logo', skipping.\n",
      "Khan\n",
      "Supporting_people_with_disabilities_\n",
      "Buzzing_city\n",
      "Buzzing_city\n",
      "Supporting_people_with_disabilities_\n",
      "Report_Center\n",
      "US\n",
      "US\n",
      "US\n",
      "Bank_of_America_resources\n",
      "Supporting_people_with_disabilities_\n",
      "Child_smiling\n",
      "Service_member\n",
      "We're_a_company_with_over_200_years_of_leadership_experience.\n",
      "Delivered_$17_billion_toward_renewable_and_cleaner_energy_initiatives\n",
      "Brian_T._Moynihan,_Chairman_of_the_Board,_Chief_Executive_Officer\n",
      "Dean_Athanasia,_President_of_Consumer_and_Small_Business\n",
      "Catherine_Bessant,_Chief_Operations_and_Technology_Officer\n",
      "Sheri_B._Bronstein,_Chief_Human_Resources_Officer\n",
      "Paul_M._Donofrio\n",
      "Anne_Finucane,_Vice_Chairman\n",
      "Geoffrey_Greener,_Chief_Risk_Officer\n",
      "Christine_Katziff,_Chief_Audit_Executive\n",
      "Katy_Knox,_President_of_Bank_of_America_Private_Bank\n",
      "David_Leitch\n",
      "Thomas_Montag,_Chief_Operating_Officer\n",
      "Thong_Nguyen,_Vice_Chairman\n",
      "Andy_Sieg,_President,_Merrill_Lynch_Wealth_Management\n",
      "Andrea_B._Smith,_Chief_Administrative_Officer\n",
      "Bruce_R._Thompson_Vice_Chairman_Chief_Executive_Officer,_BAMLI_DAC\n",
      "See_how_we_have_instrumental_in_helping_communities_and_businesses_develop_and_prosper_for_more_than_200_years.\n",
      "Report_Center\n",
      "Couldn't read: 'Bank_of_America_-_Enterprise', skipping.\n",
      "Facebook\n",
      "Twitter\n",
      "YouTube\n",
      "Couldn't read: 'Equal_Housing_Lender_Logo', skipping.\n",
      "Couldn't read: 'Bank_of_America', skipping.\n",
      "Downloaded 29 images.\n"
     ]
    }
   ],
   "source": [
    "# Download the images\n",
    "images, sizes = {}, []\n",
    "skipped_links = []\n",
    "for n, img in enumerate(soup.findAll('img')):\n",
    "    alt = img.get(\"alt\").replace(\" \", \"_\")\n",
    "    alt = alt if alt else f\"{company}_image_{n}\"\n",
    "    \n",
    "    # Read the image URL\n",
    "    path_to_image = root + img.get('src')\n",
    "    try:\n",
    "        image = io.imread(path_to_image)[..., ::-1]\n",
    "    except:\n",
    "        print(f\"Couldn't read: '{alt}', skipping.\")\n",
    "        skipped_links.append(path_to_image)\n",
    "        continue\n",
    "\n",
    "    # Keep the image URL, image array, and image size\n",
    "    print(alt)\n",
    "    images[alt] = [path_to_image, image]\n",
    "    sizes.append(image.shape)\n",
    "print(f\"Downloaded {len(images)} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common shape: (454, 686)\n",
      "Most common ratio: 662\n"
     ]
    }
   ],
   "source": [
    "# What's the most common image shape and ratio?\n",
    "get_ratio = lambda x: round(1000 * x[0] / x[1])\n",
    "most_common_shape = Counter([s[:2] for s in sizes]).most_common(1)[0][0]\n",
    "most_common_ratio = Counter(list(map(get_ratio, sizes))).most_common(1)[0][0]\n",
    "print(f\"Most common shape: {most_common_shape}\")\n",
    "print(f\"Most common ratio: {most_common_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_or_ratio_is_good(imshape):\n",
    "    return (imshape == most_common_shape) or (get_ratio(imshape) == most_common_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 15 out of 29 images.\n"
     ]
    }
   ],
   "source": [
    "# Only save images of the most common size or ratio\n",
    "num_saved = 0\n",
    "for label, image in images.items():\n",
    "    array = image[1]\n",
    "    if shape_or_ratio_is_good(array.shape[:2]):\n",
    "        fp = f\"images/{company}_{label}.jpg\"\n",
    "        cv2.imwrite(fp, array)\n",
    "        num_saved += 1\n",
    "print(f\"Saved {num_saved} out of {len(images)} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
